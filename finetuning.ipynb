{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB8-PRXsED7C",
        "outputId": "8a8699d2-1cb0-4185-d4c1-081bc26c5e7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 17725, done.\u001b[K\n",
            "remote: Counting objects: 100% (8210/8210), done.\u001b[K\n",
            "remote: Compressing objects: 100% (711/711), done.\u001b[K\n",
            "remote: Total 17725 (delta 7713), reused 7602 (delta 7499), pack-reused 9515 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17725/17725), 227.22 MiB | 13.91 MiB/s, done.\n",
            "Resolving deltas: 100% (13055/13055), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrUGU824QSPE",
        "outputId": "d751c414-b477-4383-fff3-2041579913b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ],
      "source": [
        "%cd LLaMA-Factory"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y5UZRDGrC09j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6dIDrwzQVDI",
        "outputId": "13aebe99-8fa0-49a3-e686-6ae14fca092a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yiohLsLQXFv",
        "outputId": "65894531-c56e-457b-c093-33ed9f704e95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.44.2)\n",
            "Collecting datasets<=2.21.0,>=2.16.0 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: accelerate<=0.34.2,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.34.2)\n",
            "Collecting peft<=0.12.0,>=0.11.1 (from -r requirements.txt (line 4))\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from -r requirements.txt (line 5))\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting gradio>=4.0.0 (from -r requirements.txt (line 6))\n",
            "  Downloading gradio-4.44.1-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.2.0)\n",
            "Collecting tiktoken (from -r requirements.txt (line 11))\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.20.3)\n",
            "Collecting uvicorn (from -r requirements.txt (line 13))\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2.9.2)\n",
            "Collecting fastapi (from -r requirements.txt (line 15))\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting sse-starlette (from -r requirements.txt (line 16))\n",
            "  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.7.1)\n",
            "Collecting fire (from -r requirements.txt (line 18))\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.26.4)\n",
            "Collecting av (from -r requirements.txt (line 22))\n",
            "  Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (0.24.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (3.10.8)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->-r requirements.txt (line 3)) (2.4.1+cu121)\n",
            "Collecting tyro>=0.5.11 (from trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
            "  Downloading tyro-0.8.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (3.7.1)\n",
            "Collecting ffmpy (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.1.5)\n",
            "Collecting orjson~=3.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (10.4.0)\n",
            "Collecting pydub (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.2.3)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 13)) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 13))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 14)) (2.23.4)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->-r requirements.txt (line 15))\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.1.4)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 18)) (2.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 6)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6)) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 7)) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->-r requirements.txt (line 3)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->-r requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (13.8.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5)) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (2.18.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate<=0.34.2,>=0.30.1->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (0.1.2)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.44.1-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n",
            "Downloading av-13.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.1/33.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading ruff-0.6.9-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m105.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.11-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.9/105.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114250 sha256=93af0e0300b5bb918a59f0f91d57ab723fff55ed37aa099206bae9856a100576\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "Successfully built fire\n",
            "Installing collected packages: pydub, xxhash, websockets, tomlkit, shtab, semantic-version, ruff, python-multipart, orjson, h11, fire, ffmpy, dill, av, aiofiles, uvicorn, tiktoken, starlette, multiprocess, httpcore, tyro, sse-starlette, httpx, fastapi, gradio-client, peft, gradio, datasets, trl\n",
            "Successfully installed aiofiles-23.2.1 av-13.1.0 datasets-2.21.0 dill-0.3.8 fastapi-0.115.0 ffmpy-0.4.0 fire-0.7.0 gradio-4.44.1 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 multiprocess-0.70.16 orjson-3.10.7 peft-0.12.0 pydub-0.25.1 python-multipart-0.0.12 ruff-0.6.9 semantic-version-2.10.0 shtab-1.7.1 sse-starlette-2.1.3 starlette-0.38.6 tiktoken-0.8.0 tomlkit-0.12.0 trl-0.9.6 tyro-0.8.11 uvicorn-0.31.0 websockets-12.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxPTXu0_QhbN",
        "outputId": "c7ab61c1-6dc2-4c84-ffa2-4174f99de05d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.44.1\n"
          ]
        }
      ],
      "source": [
        "!pip install bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYE89HatQltE",
        "outputId": "45035d38-7d01-4b35-eade-9ec4bf98eb2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-_m4epvhm\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-_m4epvhm\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 5ef432e4742cc505f610f8e54ac1cd2e1dfd265e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (2.32.3)\n",
            "Collecting tokenizers<0.21,>=0.20 (from transformers==4.46.0.dev0)\n",
            "  Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.46.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.46.0.dev0) (2024.8.30)\n",
            "Downloading tokenizers-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.46.0.dev0-py3-none-any.whl size=9957864 sha256=9244bedc0df914407d76ac9b11776a5285a54f3fd5cea48c81225814e25c3aca\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fivxy53g/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "Successfully installed tokenizers-0.20.0 transformers-4.46.0.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMqXTAJdQodv",
        "outputId": "12349617-5b6e-4720-8f8b-9d8bf1d1f67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<=4.45.0,>=4.41.2 (from llamafactory==0.9.1.dev0)\n",
            "  Downloading transformers-4.45.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: datasets<=2.21.0,>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.21.0)\n",
            "Requirement already satisfied: accelerate<=0.34.2,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.34.2)\n",
            "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.12.0)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.9.6)\n",
            "Requirement already satisfied: gradio>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (4.44.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.2.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.8.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.20.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.31.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.9.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.115.0)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.7.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.26.4)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (13.1.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.8.1)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.42.1)\n",
            "Collecting rouge-chinese (from llamafactory==0.9.1.dev0)\n",
            "  Downloading rouge_chinese-1.0.3-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.4.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.10.8)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.10.7)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (10.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.0.12)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.6.9)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.2.3)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (12.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.9.1.dev0) (0.38.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (2.23.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (0.20.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.8.11)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (0.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (2.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llamafactory==0.9.1.dev0) (1.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge-chinese->llamafactory==0.9.1.dev0) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.3.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (13.8.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->llamafactory==0.9.1.dev0) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.1.2)\n",
            "Downloading transformers-4.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rouge_chinese-1.0.3-py3-none-any.whl (21 kB)\n",
            "Building wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.9.1.dev0-0.editable-py3-none-any.whl size=22462 sha256=1cc80775af5568b4fed1a9f14e313490837759a6db7f7e285165f272a03bcc20\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-dq6qtk89/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: rouge-chinese, transformers, llamafactory\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.0.dev0\n",
            "    Uninstalling transformers-4.46.0.dev0:\n",
            "      Successfully uninstalled transformers-4.46.0.dev0\n",
            "Successfully installed llamafactory-0.9.1.dev0 rouge-chinese-1.0.3 transformers-4.45.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -e \".[torch, metrics]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buy91w2AQryd",
        "outputId": "d3dfa252-a0d4-47d1-f644-4b623b299e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting liger-kernel\n",
            "  Downloading liger_kernel-0.3.1-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from liger-kernel) (2.4.1+cu121)\n",
            "Collecting triton>=2.3.0 (from liger-kernel)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.2->liger-kernel) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.2->liger-kernel) (1.3.0)\n",
            "Downloading liger_kernel-0.3.1-py3-none-any.whl (58 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/58.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, liger-kernel\n",
            "Successfully installed liger-kernel-0.3.1 triton-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install liger-kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFGufx1VQ3lz"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "args = dict(\n",
        "  stage=\"sft\",\n",
        "  do_train=True,\n",
        "  model_name_or_path=\"Qwen/Qwen2-VL-2B-Instruct\",\n",
        "  dataset=\"mllm_demo,identity\",\n",
        "  template=\"qwen2_vl\",\n",
        "  finetuning_type=\"lora\",\n",
        "  lora_target=\"all\",\n",
        "  output_dir=\"qwen2vl_lora\",\n",
        "  per_device_train_batch_size=2,\n",
        "  gradient_accumulation_steps=4,\n",
        "  lr_scheduler_type=\"cosine\",\n",
        "  logging_steps=10,\n",
        "  warmup_ratio=0.1,\n",
        "  save_steps=1000,\n",
        "  learning_rate=5e-5,\n",
        "  num_train_epochs=3.0,\n",
        "  max_samples=500,\n",
        "  max_grad_norm=1.0,\n",
        "  loraplus_lr_ratio=16.0,\n",
        "  fp16=True,\n",
        "  use_liger_kernel=True,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ztZXK3YRFee"
      },
      "outputs": [],
      "source": [
        "json.dump(args, open(\"finetune.json\", \"w\", encoding=\"utf-8\"), indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMrVm34ORLv-",
        "outputId": "5392dd3e-9c06-438e-d578-10aa3b098873"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-06 07:32:40.665589: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-06 07:32:40.685334: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-06 07:32:40.691245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-06 07:32:40.706128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-06 07:32:41.841638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "10/06/2024 07:32:48 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n",
            "config.json: 100% 1.20k/1.20k [00:00<00:00, 7.64MB/s]\n",
            "[INFO|configuration_utils.py:672] 2024-10-06 07:32:49,319 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-10-06 07:32:49,320 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-10-06 07:32:49,322 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "tokenizer_config.json: 100% 4.19k/4.19k [00:00<00:00, 14.2MB/s]\n",
            "vocab.json: 100% 2.78M/2.78M [00:03<00:00, 870kB/s]\n",
            "merges.txt: 100% 1.67M/1.67M [00:00<00:00, 7.74MB/s]\n",
            "tokenizer.json: 100% 7.03M/7.03M [00:00<00:00, 9.67MB/s]\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:56,348 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:56,348 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:56,348 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:56,348 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:56,348 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:56,348 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2478] 2024-10-06 07:32:56,906 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "preprocessor_config.json: 100% 347/347 [00:00<00:00, 2.38MB/s]\n",
            "[INFO|image_processing_base.py:375] 2024-10-06 07:32:57,865 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:375] 2024-10-06 07:32:58,116 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:429] 2024-10-06 07:32:58,116 >> Image processor Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:58,369 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:58,369 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:58,369 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:58,370 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:58,370 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:32:58,370 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2478] 2024-10-06 07:32:58,746 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "chat_template.json: 100% 1.05k/1.05k [00:00<00:00, 6.46MB/s]\n",
            "[INFO|processing_utils.py:744] 2024-10-06 07:33:00,107 >> Processor Qwen2VLProcessor:\n",
            "- image_processor: Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2-VL-2B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "\n",
            "{\n",
            "  \"processor_class\": \"Qwen2VLProcessor\"\n",
            "}\n",
            "\n",
            "10/06/2024 07:33:00 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
            "10/06/2024 07:33:00 - INFO - llamafactory.data.loader - Loading dataset mllm_demo.json...\n",
            "Generating train split: 6 examples [00:00, 126.81 examples/s]\n",
            "Converting format of dataset: 100% 6/6 [00:00<00:00, 968.92 examples/s]\n",
            "10/06/2024 07:33:00 - INFO - llamafactory.data.loader - Loading dataset identity.json...\n",
            "Generating train split: 91 examples [00:00, 14743.57 examples/s]\n",
            "Converting format of dataset: 100% 91/91 [00:00<00:00, 7157.38 examples/s]\n",
            "Running tokenizer on dataset: 100% 97/97 [00:00<00:00, 715.05 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 15191, 525, 807, 30, 151645, 198, 151644, 77091, 198, 6865, 2299, 45556, 323, 87552, 89, 4554, 504, 55591, 46204, 13, 151645, 198, 151644, 872, 198, 3838, 525, 807, 3730, 30, 151645, 198, 151644, 77091, 198, 6865, 525, 31589, 389, 279, 22174, 2070, 13, 151645]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Who are they?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "They're Kane and Gretzka from Bayern Munich.<|im_end|>\n",
            "<|im_start|>user\n",
            "What are they doing?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "They are celebrating on the soccer field.<|im_end|>\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6865, 2299, 45556, 323, 87552, 89, 4554, 504, 55591, 46204, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6865, 525, 31589, 389, 279, 22174, 2070, 13, 151645]\n",
            "labels:\n",
            "They're Kane and Gretzka from Bayern Munich.<|im_end|>They are celebrating on the soccer field.<|im_end|>\n",
            "[INFO|configuration_utils.py:672] 2024-10-06 07:33:02,085 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-10-06 07:33:02,085 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-10-06 07:33:02,087 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "model.safetensors.index.json: 100% 56.4k/56.4k [00:00<00:00, 167MB/s]\n",
            "[INFO|modeling_utils.py:3726] 2024-10-06 07:33:03,151 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/model.safetensors.index.json\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/3.99G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/3.99G [00:00<06:12, 10.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 21.0M/3.99G [00:01<03:32, 18.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/3.99G [00:01<02:42, 24.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 41.9M/3.99G [00:01<02:18, 28.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/3.99G [00:02<02:04, 31.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 62.9M/3.99G [00:02<01:56, 33.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 73.4M/3.99G [00:02<01:51, 35.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 83.9M/3.99G [00:02<01:48, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/3.99G [00:03<01:44, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 105M/3.99G [00:03<01:43, 37.5MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 115M/3.99G [00:03<01:44, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 126M/3.99G [00:04<01:45, 36.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/3.99G [00:04<01:45, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 147M/3.99G [00:04<01:46, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 157M/3.99G [00:04<01:45, 36.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 168M/3.99G [00:05<01:46, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/3.99G [00:05<01:44, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 189M/3.99G [00:05<01:42, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 199M/3.99G [00:05<01:40, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 210M/3.99G [00:06<01:39, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 220M/3.99G [00:06<01:38, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 231M/3.99G [00:06<01:37, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 241M/3.99G [00:07<01:37, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 252M/3.99G [00:07<01:36, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 262M/3.99G [00:07<01:36, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 273M/3.99G [00:07<01:35, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 283M/3.99G [00:08<01:35, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 294M/3.99G [00:08<01:36, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 304M/3.99G [00:08<01:35, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 315M/3.99G [00:08<01:36, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 325M/3.99G [00:09<01:36, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 336M/3.99G [00:09<01:35, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 346M/3.99G [00:09<01:35, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 357M/3.99G [00:10<01:35, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 367M/3.99G [00:10<01:33, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 377M/3.99G [00:10<01:33, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 388M/3.99G [00:10<01:32, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 398M/3.99G [00:11<01:32, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 409M/3.99G [00:11<01:31, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 419M/3.99G [00:11<01:32, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 430M/3.99G [00:11<01:31, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 440M/3.99G [00:12<01:31, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 451M/3.99G [00:12<01:31, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 461M/3.99G [00:12<01:32, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 472M/3.99G [00:13<01:31, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 482M/3.99G [00:13<01:31, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 493M/3.99G [00:13<01:31, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 503M/3.99G [00:13<01:31, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 514M/3.99G [00:14<01:30, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 524M/3.99G [00:14<01:29, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 535M/3.99G [00:14<01:29, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 545M/3.99G [00:14<01:29, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 556M/3.99G [00:15<01:29, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 566M/3.99G [00:15<01:29, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 577M/3.99G [00:15<01:29, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 587M/3.99G [00:16<01:28, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 598M/3.99G [00:16<01:28, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 608M/3.99G [00:16<01:27, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 619M/3.99G [00:16<01:28, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 629M/3.99G [00:17<01:29, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 640M/3.99G [00:17<01:28, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 650M/3.99G [00:17<01:28, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 661M/3.99G [00:18<01:27, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 671M/3.99G [00:18<01:27, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 682M/3.99G [00:18<01:26, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 692M/3.99G [00:18<01:26, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 703M/3.99G [00:19<01:25, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 713M/3.99G [00:19<01:25, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 724M/3.99G [00:19<01:24, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 734M/3.99G [00:19<01:24, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 744M/3.99G [00:20<01:23, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 755M/3.99G [00:20<01:23, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 765M/3.99G [00:21<02:00, 26.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 776M/3.99G [00:21<01:49, 29.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 786M/3.99G [00:21<01:41, 31.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 797M/3.99G [00:21<01:35, 33.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 807M/3.99G [00:22<01:31, 34.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 818M/3.99G [00:22<01:28, 35.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 828M/3.99G [00:22<01:25, 36.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 839M/3.99G [00:23<01:24, 37.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 849M/3.99G [00:23<01:22, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 860M/3.99G [00:23<01:22, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 870M/3.99G [00:23<01:21, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 881M/3.99G [00:24<01:20, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 891M/3.99G [00:24<01:20, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 902M/3.99G [00:24<01:20, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 912M/3.99G [00:24<01:19, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 923M/3.99G [00:25<01:19, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 933M/3.99G [00:25<01:19, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 944M/3.99G [00:25<01:19, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 954M/3.99G [00:26<01:19, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 965M/3.99G [00:26<01:19, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 975M/3.99G [00:26<01:18, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 986M/3.99G [00:26<01:18, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 996M/3.99G [00:27<01:17, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.01G/3.99G [00:27<01:17, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.02G/3.99G [00:27<01:17, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.03G/3.99G [00:27<01:16, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.04G/3.99G [00:28<01:16, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.05G/3.99G [00:28<01:16, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.06G/3.99G [00:28<01:16, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.07G/3.99G [00:29<01:16, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.08G/3.99G [00:29<01:15, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.09G/3.99G [00:29<01:15, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.10G/3.99G [00:29<01:14, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.11G/3.99G [00:30<01:14, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.12G/3.99G [00:30<01:14, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.13G/3.99G [00:30<01:13, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.14G/3.99G [00:30<01:13, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.15G/3.99G [00:31<01:13, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.16G/3.99G [00:31<01:13, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.17G/3.99G [00:31<01:13, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.18G/3.99G [00:32<01:13, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.20G/3.99G [00:32<01:13, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.21G/3.99G [00:32<01:12, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.22G/3.99G [00:32<01:12, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.23G/3.99G [00:33<01:11, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.24G/3.99G [00:33<01:11, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.25G/3.99G [00:33<01:10, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.26G/3.99G [00:33<01:10, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.27G/3.99G [00:34<01:09, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.28G/3.99G [00:34<01:10, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.29G/3.99G [00:34<01:09, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.30G/3.99G [00:34<01:09, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.31G/3.99G [00:35<01:09, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.32G/3.99G [00:35<01:09, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.33G/3.99G [00:35<01:08, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.34G/3.99G [00:36<01:08, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.35G/3.99G [00:36<01:08, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.36G/3.99G [00:36<01:08, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.37G/3.99G [00:36<01:07, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.38G/3.99G [00:37<01:07, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.39G/3.99G [00:37<01:07, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.41G/3.99G [00:37<01:06, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.42G/3.99G [00:37<01:06, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.43G/3.99G [00:38<01:06, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.44G/3.99G [00:38<01:05, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.45G/3.99G [00:38<01:05, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.46G/3.99G [00:39<01:05, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.47G/3.99G [00:39<01:05, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.48G/3.99G [00:39<01:05, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.49G/3.99G [00:39<01:06, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.50G/3.99G [00:40<01:27, 28.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.51G/3.99G [00:40<01:21, 30.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.52G/3.99G [00:41<01:16, 32.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.53G/3.99G [00:41<01:12, 33.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.54G/3.99G [00:41<01:09, 35.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.55G/3.99G [00:41<01:07, 36.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.56G/3.99G [00:42<01:05, 37.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.57G/3.99G [00:42<01:04, 37.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.58G/3.99G [00:42<01:03, 37.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.59G/3.99G [00:42<01:02, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.60G/3.99G [00:43<01:02, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.61G/3.99G [00:43<01:01, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 1.63G/3.99G [00:43<01:01, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 1.64G/3.99G [00:44<01:00, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 1.65G/3.99G [00:44<01:00, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.66G/3.99G [00:44<01:00, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.67G/3.99G [00:44<01:00, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.68G/3.99G [00:45<01:00, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.69G/3.99G [00:45<01:00, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.70G/3.99G [00:45<00:59, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.71G/3.99G [00:45<00:59, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.72G/3.99G [00:46<00:59, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.73G/3.99G [00:46<00:58, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.74G/3.99G [00:46<00:58, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.75G/3.99G [00:47<00:57, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.76G/3.99G [00:47<00:57, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.77G/3.99G [00:47<00:57, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.78G/3.99G [00:47<00:56, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.79G/3.99G [00:48<00:56, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.80G/3.99G [00:48<00:56, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.81G/3.99G [00:48<00:56, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 1.82G/3.99G [00:48<00:56, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 1.84G/3.99G [00:49<00:56, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 1.85G/3.99G [00:49<00:55, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.86G/3.99G [00:49<00:56, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.87G/3.99G [00:50<00:55, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.88G/3.99G [00:50<00:54, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.89G/3.99G [00:50<00:54, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 1.90G/3.99G [00:50<00:54, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 1.91G/3.99G [00:51<00:54, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 1.92G/3.99G [00:51<00:53, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 1.93G/3.99G [00:51<00:53, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.94G/3.99G [00:52<01:11, 28.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.95G/3.99G [00:52<01:05, 31.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.96G/3.99G [00:52<01:01, 32.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.97G/3.99G [00:53<01:00, 33.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 1.98G/3.99G [00:53<00:58, 34.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 1.99G/3.99G [00:53<00:56, 35.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.00G/3.99G [00:53<00:54, 36.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.01G/3.99G [00:54<00:53, 37.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.02G/3.99G [00:54<00:52, 37.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.03G/3.99G [00:54<00:51, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.04G/3.99G [00:54<00:50, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.06G/3.99G [00:55<00:50, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.07G/3.99G [00:55<00:49, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.08G/3.99G [00:55<00:49, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.09G/3.99G [00:56<00:49, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.10G/3.99G [00:56<00:49, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.11G/3.99G [00:56<00:48, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.12G/3.99G [00:56<00:48, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.13G/3.99G [00:57<00:48, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.14G/3.99G [00:57<00:47, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.15G/3.99G [00:57<00:47, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.16G/3.99G [00:57<00:47, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.17G/3.99G [00:58<00:46, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.18G/3.99G [00:58<00:46, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.19G/3.99G [00:58<00:46, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.20G/3.99G [00:59<00:46, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.21G/3.99G [00:59<00:45, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.22G/3.99G [00:59<00:45, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.23G/3.99G [00:59<00:45, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.24G/3.99G [01:00<00:45, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.25G/3.99G [01:00<00:44, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.26G/3.99G [01:00<00:44, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.28G/3.99G [01:00<00:44, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.29G/3.99G [01:01<00:44, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.30G/3.99G [01:01<00:43, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.31G/3.99G [01:01<00:43, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.32G/3.99G [01:02<00:43, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.33G/3.99G [01:02<00:43, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.34G/3.99G [01:02<00:43, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.35G/3.99G [01:02<00:42, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.36G/3.99G [01:03<00:42, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.37G/3.99G [01:03<00:42, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.38G/3.99G [01:03<00:42, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.39G/3.99G [01:03<00:41, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.40G/3.99G [01:04<00:41, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.41G/3.99G [01:04<00:40, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 2.42G/3.99G [01:04<00:40, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 2.43G/3.99G [01:05<00:40, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 2.44G/3.99G [01:05<00:40, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.45G/3.99G [01:05<00:39, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.46G/3.99G [01:05<00:39, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.47G/3.99G [01:06<00:39, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.49G/3.99G [01:06<00:39, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.50G/3.99G [01:06<00:38, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.51G/3.99G [01:06<00:38, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.52G/3.99G [01:07<00:38, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.53G/3.99G [01:07<00:38, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.54G/3.99G [01:07<00:37, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.55G/3.99G [01:08<00:37, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.56G/3.99G [01:08<00:36, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.57G/3.99G [01:08<00:36, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 2.58G/3.99G [01:08<00:36, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 2.59G/3.99G [01:09<00:36, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 2.60G/3.99G [01:09<00:35, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 2.61G/3.99G [01:09<00:35, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.62G/3.99G [01:09<00:35, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.63G/3.99G [01:10<00:35, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.64G/3.99G [01:10<00:34, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.65G/3.99G [01:10<00:34, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.66G/3.99G [01:11<00:34, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.67G/3.99G [01:11<00:34, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.68G/3.99G [01:11<00:34, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.69G/3.99G [01:11<00:34, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.71G/3.99G [01:12<00:33, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.72G/3.99G [01:12<00:33, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.73G/3.99G [01:12<00:32, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.74G/3.99G [01:12<00:32, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.75G/3.99G [01:13<00:32, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.76G/3.99G [01:13<00:32, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.77G/3.99G [01:13<00:31, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.78G/3.99G [01:14<00:31, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.79G/3.99G [01:14<00:30, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.80G/3.99G [01:14<00:30, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.81G/3.99G [01:14<00:30, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 2.82G/3.99G [01:15<00:30, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 2.83G/3.99G [01:15<00:30, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 2.84G/3.99G [01:15<00:30, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.85G/3.99G [01:15<00:29, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.86G/3.99G [01:16<00:29, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.87G/3.99G [01:16<00:29, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.88G/3.99G [01:16<00:29, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.89G/3.99G [01:17<00:28, 37.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.90G/3.99G [01:17<00:28, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.92G/3.99G [01:17<00:27, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.93G/3.99G [01:17<00:27, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.94G/3.99G [01:18<00:27, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.95G/3.99G [01:18<00:27, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.96G/3.99G [01:18<00:26, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.97G/3.99G [01:18<00:26, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 2.98G/3.99G [01:19<00:26, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 2.99G/3.99G [01:19<00:25, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.00G/3.99G [01:19<00:25, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.01G/3.99G [01:20<00:25, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.02G/3.99G [01:20<00:25, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.03G/3.99G [01:20<00:24, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.04G/3.99G [01:20<00:24, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.05G/3.99G [01:21<00:24, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.06G/3.99G [01:21<00:23, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.07G/3.99G [01:21<00:23, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.08G/3.99G [01:21<00:23, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.09G/3.99G [01:22<00:23, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.10G/3.99G [01:22<00:23, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.11G/3.99G [01:22<00:22, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.12G/3.99G [01:23<00:22, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.14G/3.99G [01:23<00:22, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.15G/3.99G [01:23<00:29, 28.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.16G/3.99G [01:24<00:26, 31.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.17G/3.99G [01:24<00:24, 33.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.18G/3.99G [01:24<00:23, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.19G/3.99G [01:24<00:22, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.20G/3.99G [01:25<00:21, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.21G/3.99G [01:25<00:20, 37.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.22G/3.99G [01:25<00:20, 37.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.23G/3.99G [01:26<00:19, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.24G/3.99G [01:26<00:19, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.25G/3.99G [01:26<00:19, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 3.26G/3.99G [01:26<00:18, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 3.27G/3.99G [01:27<00:18, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 3.28G/3.99G [01:27<00:18, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.29G/3.99G [01:27<00:18, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.30G/3.99G [01:27<00:17, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.31G/3.99G [01:28<00:17, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.32G/3.99G [01:28<00:17, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.33G/3.99G [01:28<00:16, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.34G/3.99G [01:29<00:16, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.36G/3.99G [01:29<00:16, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.37G/3.99G [01:29<00:16, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.38G/3.99G [01:29<00:16, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.39G/3.99G [01:30<00:15, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.40G/3.99G [01:30<00:15, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.41G/3.99G [01:30<00:15, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.42G/3.99G [01:31<00:15, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.43G/3.99G [01:31<00:14, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.44G/3.99G [01:31<00:14, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.45G/3.99G [01:31<00:13, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.46G/3.99G [01:32<00:13, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.47G/3.99G [01:32<00:13, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.48G/3.99G [01:32<00:13, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.49G/3.99G [01:32<00:12, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.50G/3.99G [01:33<00:12, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.51G/3.99G [01:33<00:12, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.52G/3.99G [01:33<00:12, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.53G/3.99G [01:33<00:11, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.54G/3.99G [01:34<00:11, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.55G/3.99G [01:34<00:11, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.57G/3.99G [01:34<00:11, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.58G/3.99G [01:35<00:10, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.59G/3.99G [01:35<00:10, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.60G/3.99G [01:35<00:10, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.61G/3.99G [01:35<00:09, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.62G/3.99G [01:36<00:09, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.63G/3.99G [01:36<00:09, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.64G/3.99G [01:36<00:09, 38.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.65G/3.99G [01:36<00:08, 38.9MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.66G/3.99G [01:37<00:08, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.67G/3.99G [01:37<00:08, 38.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.68G/3.99G [01:37<00:08, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.69G/3.99G [01:38<00:07, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.70G/3.99G [01:38<00:07, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.71G/3.99G [01:38<00:07, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.72G/3.99G [01:38<00:06, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 3.73G/3.99G [01:39<00:06, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 3.74G/3.99G [01:39<00:06, 38.6MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 3.75G/3.99G [01:39<00:06, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 3.76G/3.99G [01:39<00:05, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 3.77G/3.99G [01:40<00:05, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 3.79G/3.99G [01:40<00:05, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 3.80G/3.99G [01:40<00:05, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 3.81G/3.99G [01:41<00:04, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 3.82G/3.99G [01:41<00:04, 38.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 3.83G/3.99G [01:41<00:04, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 3.84G/3.99G [01:41<00:03, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 3.85G/3.99G [01:42<00:03, 38.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 3.86G/3.99G [01:42<00:03, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 3.87G/3.99G [01:42<00:03, 38.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 3.88G/3.99G [01:42<00:02, 38.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.89G/3.99G [01:43<00:02, 38.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.90G/3.99G [01:43<00:03, 29.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.91G/3.99G [01:44<00:02, 31.3MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.92G/3.99G [01:44<00:02, 33.4MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 3.93G/3.99G [01:44<00:01, 34.7MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 3.94G/3.99G [01:44<00:01, 35.8MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 3.95G/3.99G [01:45<00:00, 36.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 3.96G/3.99G [01:45<00:00, 37.2MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 3.97G/3.99G [01:45<00:00, 37.5MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 3.98G/3.99G [01:45<00:00, 38.0MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 3.99G/3.99G [01:46<00:00, 37.6MB/s]\n",
            "Downloading shards:  50% 1/2 [01:46<01:46, 106.84s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/429M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   2% 10.5M/429M [00:00<00:10, 39.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   5% 21.0M/429M [00:00<00:10, 39.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 31.5M/429M [00:00<00:10, 38.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 41.9M/429M [00:01<00:10, 38.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 52.4M/429M [00:01<00:09, 38.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 62.9M/429M [00:01<00:09, 38.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  17% 73.4M/429M [00:01<00:09, 38.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 83.9M/429M [00:02<00:08, 38.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 94.4M/429M [00:02<00:08, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 105M/429M [00:02<00:08, 38.6MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 115M/429M [00:02<00:08, 38.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 126M/429M [00:03<00:07, 38.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 136M/429M [00:03<00:07, 38.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 147M/429M [00:03<00:07, 38.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 157M/429M [00:04<00:07, 38.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 168M/429M [00:04<00:06, 38.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 178M/429M [00:04<00:06, 38.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 189M/429M [00:04<00:06, 38.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 199M/429M [00:05<00:06, 37.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 210M/429M [00:05<00:05, 37.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 220M/429M [00:05<00:05, 36.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 231M/429M [00:06<00:05, 36.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  56% 241M/429M [00:06<00:05, 37.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 252M/429M [00:06<00:04, 37.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 262M/429M [00:06<00:04, 38.2MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 273M/429M [00:07<00:04, 38.1MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  66% 283M/429M [00:07<00:03, 38.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 294M/429M [00:07<00:03, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 304M/429M [00:07<00:03, 38.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 315M/429M [00:08<00:02, 38.6MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 325M/429M [00:08<00:02, 38.8MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 336M/429M [00:08<00:02, 38.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 346M/429M [00:09<00:02, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 357M/429M [00:09<00:01, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  85% 367M/429M [00:09<00:01, 38.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 377M/429M [00:09<00:01, 38.0MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  90% 388M/429M [00:10<00:01, 38.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 398M/429M [00:10<00:00, 38.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 409M/429M [00:10<00:00, 38.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 419M/429M [00:10<00:00, 38.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 429M/429M [00:11<00:00, 38.2MB/s]\n",
            "Downloading shards: 100% 2/2 [01:58<00:00, 59.30s/it]\n",
            "[INFO|modeling_utils.py:1622] 2024-10-06 07:35:01,756 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:1099] 2024-10-06 07:35:01,758 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645\n",
            "}\n",
            "\n",
            "[WARNING|logging.py:328] 2024-10-06 07:35:01,880 >> `Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
            "Loading checkpoint shards: 100% 2/2 [00:20<00:00, 10.35s/it]\n",
            "[INFO|modeling_utils.py:4568] 2024-10-06 07:35:22,736 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:4576] 2024-10-06 07:35:22,736 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2-VL-2B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
            "generation_config.json: 100% 272/272 [00:00<00:00, 1.80MB/s]\n",
            "[INFO|configuration_utils.py:1054] 2024-10-06 07:35:23,217 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/generation_config.json\n",
            "[INFO|configuration_utils.py:1099] 2024-10-06 07:35:23,217 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"temperature\": 0.01,\n",
            "  \"top_k\": 1,\n",
            "  \"top_p\": 0.001\n",
            "}\n",
            "\n",
            "10/06/2024 07:35:23 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
            "10/06/2024 07:35:23 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "10/06/2024 07:35:23 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
            "10/06/2024 07:35:23 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
            "10/06/2024 07:35:23 - INFO - llamafactory.model.model_utils.misc - Found linear modules: down_proj,gate_proj,v_proj,o_proj,k_proj,q_proj,up_proj\n",
            "10/06/2024 07:35:24 - INFO - llamafactory.model.loader - trainable params: 9,232,384 || all params: 2,218,217,984 || trainable%: 0.4162\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:494: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "[WARNING|trainer.py:477] 2024-10-06 07:35:24,527 >> The model is not an instance of PreTrainedModel. No liger kernels will be applied.\n",
            "[INFO|trainer.py:667] 2024-10-06 07:35:24,637 >> Using auto half precision backend\n",
            "10/06/2024 07:35:25 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
            "[INFO|trainer.py:2243] 2024-10-06 07:35:25,540 >> ***** Running training *****\n",
            "[INFO|trainer.py:2244] 2024-10-06 07:35:25,540 >>   Num examples = 97\n",
            "[INFO|trainer.py:2245] 2024-10-06 07:35:25,540 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2246] 2024-10-06 07:35:25,540 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:2249] 2024-10-06 07:35:25,540 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:2250] 2024-10-06 07:35:25,540 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2251] 2024-10-06 07:35:25,540 >>   Total optimization steps = 36\n",
            "[INFO|trainer.py:2252] 2024-10-06 07:35:25,545 >>   Number of trainable parameters = 9,232,384\n",
            "  0% 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "{'loss': 1.8186, 'grad_norm': 1.240362524986267, 'learning_rate': 4.5786740307563636e-05, 'epoch': 0.82}\n",
            "{'loss': 0.9053, 'grad_norm': 1.425156593322754, 'learning_rate': 2.5e-05, 'epoch': 1.63}\n",
            "{'loss': 0.7051, 'grad_norm': 0.7807074785232544, 'learning_rate': 4.213259692436367e-06, 'epoch': 2.45}\n",
            "100% 36/36 [00:56<00:00,  1.41s/it][INFO|trainer.py:3705] 2024-10-06 07:36:22,215 >> Saving model checkpoint to qwen2vl_lora/checkpoint-36\n",
            "[INFO|configuration_utils.py:672] 2024-10-06 07:36:22,744 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-10-06 07:36:22,744 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-10-06 07:36:22,746 >> Model config Qwen2VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2649] 2024-10-06 07:36:22,848 >> tokenizer config file saved in qwen2vl_lora/checkpoint-36/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2658] 2024-10-06 07:36:22,848 >> Special tokens file saved in qwen2vl_lora/checkpoint-36/special_tokens_map.json\n",
            "[INFO|image_processing_base.py:258] 2024-10-06 07:36:23,289 >> Image processor saved in qwen2vl_lora/checkpoint-36/preprocessor_config.json\n",
            "[INFO|trainer.py:2505] 2024-10-06 07:36:23,289 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 57.7443, 'train_samples_per_second': 5.039, 'train_steps_per_second': 0.623, 'train_loss': 1.058449341191186, 'epoch': 2.94}\n",
            "100% 36/36 [00:57<00:00,  1.60s/it]\n",
            "[INFO|image_processing_base.py:258] 2024-10-06 07:36:23,293 >> Image processor saved in qwen2vl_lora/preprocessor_config.json\n",
            "[INFO|trainer.py:3705] 2024-10-06 07:36:23,294 >> Saving model checkpoint to qwen2vl_lora\n",
            "[INFO|configuration_utils.py:672] 2024-10-06 07:36:23,807 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-10-06 07:36:23,807 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-10-06 07:36:23,809 >> Model config Qwen2VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2649] 2024-10-06 07:36:23,891 >> tokenizer config file saved in qwen2vl_lora/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2658] 2024-10-06 07:36:23,891 >> Special tokens file saved in qwen2vl_lora/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =     2.9388\n",
            "  total_flos               =   230785GF\n",
            "  train_loss               =     1.0584\n",
            "  train_runtime            = 0:00:57.74\n",
            "  train_samples_per_second =      5.039\n",
            "  train_steps_per_second   =      0.623\n",
            "[INFO|modelcard.py:449] 2024-10-06 07:36:24,092 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ],
      "source": [
        "!llamafactory-cli train finetune.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = dict(\n",
        "  model_name_or_path=\"Qwen/Qwen2-VL-2B-Instruct\", # use official non-quantized Llama-3-8B-Instruct model\n",
        "  adapter_name_or_path=\"qwen2vl_lora\",            # load the saved LoRA adapters\n",
        "  template=\"qwen2_vl\",                     # same to the one in training\n",
        "  finetuning_type=\"lora\",                  # same to the one in training\n",
        "  export_dir=\"qwen2vl_2b_instruct_lora_merged\",              # the path to save the merged model\n",
        "  export_size=2,                       # the file shard size (in GB) of the merged model\n",
        "  export_device=\"cpu\",                    # the device used in export, can be chosen from `cpu` and `cuda`\n",
        "  #export_hub_model_id=\"your_id/your_model\",         # the Hugging Face hub ID to upload model\n",
        ")\n"
      ],
      "metadata": {
        "id": "embC_y1Zx6dX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(args, open(\"merge_qwen2vl.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "%cd /content/LLaMA-Factory/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03w6NA5fyaqB",
        "outputId": "e5c697b4-16fc-413c-aa93-c044fa0e2fc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!llamafactory-cli export merge_qwen2vl.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLqtWPR3ybLI",
        "outputId": "00071dc2-f3f5-466a-b9a9-58ee6448a3b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-06 07:45:05.414602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-06 07:45:05.434445: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-06 07:45:05.440470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-06 07:45:05.454569: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-10-06 07:45:06.789956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[INFO|configuration_utils.py:672] 2024-10-06 07:45:14,898 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-10-06 07:45:14,900 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-10-06 07:45:14,902 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:15,135 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:15,135 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:15,135 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:15,135 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:15,135 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:15,135 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2478] 2024-10-06 07:45:15,525 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|image_processing_base.py:375] 2024-10-06 07:45:16,281 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:375] 2024-10-06 07:45:16,511 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:429] 2024-10-06 07:45:16,512 >> Image processor Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:16,740 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:16,740 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:16,740 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:16,740 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:16,741 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2214] 2024-10-06 07:45:16,741 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2478] 2024-10-06 07:45:17,100 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|processing_utils.py:744] 2024-10-06 07:45:18,215 >> Processor Qwen2VLProcessor:\n",
            "- image_processor: Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2-VL-2B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "\n",
            "{\n",
            "  \"processor_class\": \"Qwen2VLProcessor\"\n",
            "}\n",
            "\n",
            "10/06/2024 07:45:18 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
            "[INFO|configuration_utils.py:672] 2024-10-06 07:45:18,504 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/config.json\n",
            "[WARNING|modeling_rope_utils.py:379] 2024-10-06 07:45:18,504 >> Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n",
            "[INFO|configuration_utils.py:739] 2024-10-06 07:45:18,505 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"rope_type\": \"default\",\n",
            "    \"type\": \"default\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "10/06/2024 07:45:18 - INFO - llamafactory.model.patcher - Using KV cache for faster generation.\n",
            "[INFO|modeling_utils.py:3726] 2024-10-06 07:45:18,540 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/model.safetensors.index.json\n",
            "[INFO|modeling_utils.py:1622] 2024-10-06 07:45:18,542 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1099] 2024-10-06 07:45:18,544 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645\n",
            "}\n",
            "\n",
            "[WARNING|logging.py:328] 2024-10-06 07:45:18,566 >> `Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n",
            "Loading checkpoint shards: 100% 2/2 [00:00<00:00,  2.66it/s]\n",
            "[INFO|modeling_utils.py:4568] 2024-10-06 07:45:19,478 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:4576] 2024-10-06 07:45:19,478 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2-VL-2B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
            "[INFO|configuration_utils.py:1054] 2024-10-06 07:45:19,760 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/aca78372505e6cb469c4fa6a35c60265b00ff5a4/generation_config.json\n",
            "[INFO|configuration_utils.py:1099] 2024-10-06 07:45:19,760 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"temperature\": 0.01,\n",
            "  \"top_k\": 1,\n",
            "  \"top_p\": 0.001\n",
            "}\n",
            "\n",
            "10/06/2024 07:45:19 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "10/06/2024 07:45:39 - INFO - llamafactory.model.adapter - Merged 1 adapter(s).\n",
            "10/06/2024 07:45:39 - INFO - llamafactory.model.adapter - Loaded adapter(s): qwen2vl_lora\n",
            "10/06/2024 07:45:39 - INFO - llamafactory.model.loader - all params: 2,208,985,600\n",
            "10/06/2024 07:45:39 - INFO - llamafactory.train.tuner - Convert model dtype to: torch.bfloat16.\n",
            "[INFO|configuration_utils.py:407] 2024-10-06 07:45:39,420 >> Configuration saved in qwen2vl_2b_instruct_lora_merged/config.json\n",
            "[INFO|configuration_utils.py:868] 2024-10-06 07:45:39,421 >> Configuration saved in qwen2vl_2b_instruct_lora_merged/generation_config.json\n",
            "[INFO|modeling_utils.py:2838] 2024-10-06 07:47:12,638 >> The model is bigger than the maximum size per checkpoint (2GB) and is going to be split in 3 checkpoint shards. You can find where each parameters has been saved in the index located at qwen2vl_2b_instruct_lora_merged/model.safetensors.index.json.\n",
            "[INFO|tokenization_utils_base.py:2649] 2024-10-06 07:47:12,640 >> tokenizer config file saved in qwen2vl_2b_instruct_lora_merged/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2658] 2024-10-06 07:47:12,640 >> Special tokens file saved in qwen2vl_2b_instruct_lora_merged/special_tokens_map.json\n",
            "[INFO|image_processing_base.py:258] 2024-10-06 07:47:12,967 >> Image processor saved in qwen2vl_2b_instruct_lora_merged/preprocessor_config.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_model_path = \"/content/LLaMA-Factory/qwen2vl_2b_instruct_lora_merged\""
      ],
      "metadata": {
        "id": "T7sO69BNyeNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hf_model_repo = \"Anamta98/Qwen2-VL-2B-Instruct-LoRA-FT\""
      ],
      "metadata": {
        "id": "1qmd3M4HzGKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "6c431f02ab2e4d078c3617834653205d",
            "c9b4537d30504e51b39a78e690cd4755",
            "5ad1a271c4284317836ad2a812c212ad",
            "85bf9125958148babe9932b7725f3341",
            "3f3c3a293417426c87938c2a3d2631e1",
            "8bf30061bc7548d583e9882ddddbe431",
            "f80e7e1f19224c2a87027621ebba07af",
            "0a0a6cd900a348bb82a7cf2e624c793b",
            "2a67c3cbd079422aa855734b5282167d",
            "fd258acf33444905bad9b313625a7993",
            "55ff246a411642d3b077107068ff9876",
            "ab57e575f55c42279248892c39da98d5",
            "08d4a918733847ccbc86c7ee3c5966cb",
            "8e7da6e2d30e46fa80ab6f75456a311a",
            "8c74fa043541408f987e03ae9ece6a05",
            "972e127929544543a040bdaebb387112",
            "8ae16a0b87a7447f8eb0cff69c029734",
            "83ae7a182a72464ca0714adb84e8e7b3",
            "7457171c27c646adaae1fab73f5c3bce",
            "a4e2f2e9ac864f02ae1ebfb22d0be5dd",
            "e113c6447a3f4a4a89ea89e2c135f846",
            "f54e748714184f23a89a279623b69f39",
            "970c9bf18e9e4e89b785007e9c0eef5e",
            "382caf5d761f46f5b38d2f966f183ec0",
            "50821cd9fbdd44648a0aa1daac0da500",
            "c821fb9c5f23469792ef6cba249eeffa",
            "d2fb3f429a014860ae4eda411c65cb8e",
            "ac0c25c8e7274f3c9d80ef59c9583be5",
            "456957c0a9744ad7bdc13c92cef0f2f6",
            "97f8fa7dc6444a26be1a6ba02f2bb353",
            "c736254aef1e40e38b4cc73def804794",
            "3db48d19c585465bb900e10276a8fd38"
          ]
        },
        "id": "l-69njwpzmOE",
        "outputId": "ebde1887-d00e-4f7b-ccdd-efac7da69d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c431f02ab2e4d078c3617834653205d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi, HfFolder, Repository"
      ],
      "metadata": {
        "id": "m97jR4Ckz-9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create an instance of HfApi\n",
        "api = HfApi()\n"
      ],
      "metadata": {
        "id": "eOfVP6-I0CG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api.upload_folder(\n",
        "    folder_path=final_model_path,    # The folder containing the model files\n",
        "    repo_id=hf_model_repo,                # Your authentication token\n",
        "    commit_message=\"Initial model upload\"  # Optional commit message\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371,
          "referenced_widgets": [
            "e64acd4d1137419e872c292f2b3bdca5",
            "03edf67f57bf476eb2a43537eaa678bf",
            "730ba64da7dd475eb4096fcdc89154a0",
            "21d4e024f6b040c797a10e7c0c135a1b",
            "cb0e44802ac1473fa50a4c5cde9872e0",
            "3afd784c7adc4048939cc729f0a44538",
            "e107534527434f90b347464f2e19414a",
            "13a2e62e04e2481e88fba1e3c763fbcd",
            "ffe4d8751f7e41fc8a03a0fec05f737d",
            "41424436154a4f649a44580ed3d5226e",
            "24810aa1f5864a61a51b3323540b8028",
            "be9a26726b0e470c85f8d807a899085d",
            "8d6d0d92d6814d8da167134c9b8170a8",
            "c2b331d7433c4766ba5842276c917194",
            "6927f4575b9746fbb045be1170f5c7b0",
            "39601551ccbb463b97aad50ddc8af02f",
            "0e856ae77b234e4e808686af82f32c2d",
            "299fb129ee3e48a4b0a177be12798ea7",
            "fe776097aac840798fb2807613b2da79",
            "9f845a7e1dbb49c1b92d72e834d18253",
            "dae7109032a245509cde1872516a5ac1",
            "5d567f381732494aac5b3b2866055f0b",
            "2f0fb66a4688437594cf35f18313d6ce",
            "e27661ae084f474da835107076884c96",
            "ca436c904c264211b2ba12ece304e322",
            "b4254326fe6f439db62e120c0fccf210",
            "50b05093f2c14221be19773d0c55e845",
            "9cdc013c76934cd188ea84f7c1a6e98a",
            "dea3fce4e6b14461b2777cdf6e324969",
            "2d4925949c5842208210f60e259a3885",
            "52fe0552a09e4f30a79320a33df349b8",
            "b1d72a07c5e84e08a935f5bddb6cefc1",
            "fa69746380be48e88d8009a19df7d1cf",
            "afc27e4e05eb4c7796e892cc17c742c4",
            "62326fef6290413b9d4a42eb7a4ac88f",
            "d3d8fd42b6f14310be510c0e7c6ab730",
            "54801faf9f45432ca704466c1904c205",
            "ca44be2a94e446128c8fe31b5e0993c1",
            "afcbefe2b6344557864ef383add76ece",
            "8386bd12e24a47aba238d0eb0c351300",
            "162a66ea8fd146539373a693ebeaed7a",
            "e3d599f96ed545019be52294a1d741a4",
            "e1b849c9d53546c590ae21ca3760a099",
            "f6ae6d6062a04064b383587c27d14baf",
            "4fa3ab92428c401c8b2489c716cd7368",
            "5c34eab4d0f94fd3a1cee8c9cf7092eb",
            "b4807baf9dd748d5aac967a08d37cf04",
            "70fa4ebae49c41b0a937748d021ce025",
            "d753f229695246c194458a9d34fcd412",
            "f3d259a32d1245cbaad4a1a2655e74bf",
            "e5ec7282ac174ff1bef045ed124a7bc9",
            "4479cd0b3d494cccb901f719a9ca6605",
            "87e764cc25644dc296d4622952e20965",
            "a85c59d70e4f452fabc28fa61c805e2f",
            "8792cdea158544619994a7137d24a088"
          ]
        },
        "id": "czgA9Go90Fm9",
        "outputId": "9607dd3d-fb2d-4cf7-986b-2fa14f9b29de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00001-of-00003.safetensors:   0%|          | 0.00/2.00G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e64acd4d1137419e872c292f2b3bdca5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00003-of-00003.safetensors:   0%|          | 0.00/429M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be9a26726b0e470c85f8d807a899085d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model-00002-of-00003.safetensors:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f0fb66a4688437594cf35f18313d6ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload 4 LFS files:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afc27e4e05eb4c7796e892cc17c742c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4fa3ab92428c401c8b2489c716cd7368"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Anamta98/Qwen2-VL-2B-Instruct-LoRA-FT/commit/213dfd520c4ee4e8fbbac36310cd00f67be38b85', commit_message='Initial model upload', commit_description='', oid='213dfd520c4ee4e8fbbac36310cd00f67be38b85', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Model pushed to: {hf_model_repo}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9KbwDpl0wK2",
        "outputId": "868fe79a-0efa-44ac-b1ce-90d9d805a70b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model pushed to: Anamta98/Qwen2-VL-2B-Instruct-LoRA-FT\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c431f02ab2e4d078c3617834653205d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e113c6447a3f4a4a89ea89e2c135f846",
              "IPY_MODEL_f54e748714184f23a89a279623b69f39",
              "IPY_MODEL_970c9bf18e9e4e89b785007e9c0eef5e",
              "IPY_MODEL_382caf5d761f46f5b38d2f966f183ec0"
            ],
            "layout": "IPY_MODEL_f80e7e1f19224c2a87027621ebba07af"
          }
        },
        "c9b4537d30504e51b39a78e690cd4755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a0a6cd900a348bb82a7cf2e624c793b",
            "placeholder": "​",
            "style": "IPY_MODEL_2a67c3cbd079422aa855734b5282167d",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "5ad1a271c4284317836ad2a812c212ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_fd258acf33444905bad9b313625a7993",
            "placeholder": "​",
            "style": "IPY_MODEL_55ff246a411642d3b077107068ff9876",
            "value": ""
          }
        },
        "85bf9125958148babe9932b7725f3341": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_ab57e575f55c42279248892c39da98d5",
            "style": "IPY_MODEL_08d4a918733847ccbc86c7ee3c5966cb",
            "value": true
          }
        },
        "3f3c3a293417426c87938c2a3d2631e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8e7da6e2d30e46fa80ab6f75456a311a",
            "style": "IPY_MODEL_8c74fa043541408f987e03ae9ece6a05",
            "tooltip": ""
          }
        },
        "8bf30061bc7548d583e9882ddddbe431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972e127929544543a040bdaebb387112",
            "placeholder": "​",
            "style": "IPY_MODEL_8ae16a0b87a7447f8eb0cff69c029734",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "f80e7e1f19224c2a87027621ebba07af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0a0a6cd900a348bb82a7cf2e624c793b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a67c3cbd079422aa855734b5282167d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd258acf33444905bad9b313625a7993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55ff246a411642d3b077107068ff9876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab57e575f55c42279248892c39da98d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08d4a918733847ccbc86c7ee3c5966cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8e7da6e2d30e46fa80ab6f75456a311a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c74fa043541408f987e03ae9ece6a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "972e127929544543a040bdaebb387112": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae16a0b87a7447f8eb0cff69c029734": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83ae7a182a72464ca0714adb84e8e7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7457171c27c646adaae1fab73f5c3bce",
            "placeholder": "​",
            "style": "IPY_MODEL_a4e2f2e9ac864f02ae1ebfb22d0be5dd",
            "value": "Connecting..."
          }
        },
        "7457171c27c646adaae1fab73f5c3bce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4e2f2e9ac864f02ae1ebfb22d0be5dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e113c6447a3f4a4a89ea89e2c135f846": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50821cd9fbdd44648a0aa1daac0da500",
            "placeholder": "​",
            "style": "IPY_MODEL_c821fb9c5f23469792ef6cba249eeffa",
            "value": "Token is valid (permission: fineGrained)."
          }
        },
        "f54e748714184f23a89a279623b69f39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2fb3f429a014860ae4eda411c65cb8e",
            "placeholder": "​",
            "style": "IPY_MODEL_ac0c25c8e7274f3c9d80ef59c9583be5",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "970c9bf18e9e4e89b785007e9c0eef5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_456957c0a9744ad7bdc13c92cef0f2f6",
            "placeholder": "​",
            "style": "IPY_MODEL_97f8fa7dc6444a26be1a6ba02f2bb353",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "382caf5d761f46f5b38d2f966f183ec0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c736254aef1e40e38b4cc73def804794",
            "placeholder": "​",
            "style": "IPY_MODEL_3db48d19c585465bb900e10276a8fd38",
            "value": "Login successful"
          }
        },
        "50821cd9fbdd44648a0aa1daac0da500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c821fb9c5f23469792ef6cba249eeffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2fb3f429a014860ae4eda411c65cb8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0c25c8e7274f3c9d80ef59c9583be5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "456957c0a9744ad7bdc13c92cef0f2f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97f8fa7dc6444a26be1a6ba02f2bb353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c736254aef1e40e38b4cc73def804794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3db48d19c585465bb900e10276a8fd38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e64acd4d1137419e872c292f2b3bdca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03edf67f57bf476eb2a43537eaa678bf",
              "IPY_MODEL_730ba64da7dd475eb4096fcdc89154a0",
              "IPY_MODEL_21d4e024f6b040c797a10e7c0c135a1b"
            ],
            "layout": "IPY_MODEL_cb0e44802ac1473fa50a4c5cde9872e0"
          }
        },
        "03edf67f57bf476eb2a43537eaa678bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3afd784c7adc4048939cc729f0a44538",
            "placeholder": "​",
            "style": "IPY_MODEL_e107534527434f90b347464f2e19414a",
            "value": "model-00001-of-00003.safetensors: 100%"
          }
        },
        "730ba64da7dd475eb4096fcdc89154a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a2e62e04e2481e88fba1e3c763fbcd",
            "max": 1995539928,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ffe4d8751f7e41fc8a03a0fec05f737d",
            "value": 1995539928
          }
        },
        "21d4e024f6b040c797a10e7c0c135a1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41424436154a4f649a44580ed3d5226e",
            "placeholder": "​",
            "style": "IPY_MODEL_24810aa1f5864a61a51b3323540b8028",
            "value": " 2.00G/2.00G [01:20&lt;00:00, 28.0MB/s]"
          }
        },
        "cb0e44802ac1473fa50a4c5cde9872e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3afd784c7adc4048939cc729f0a44538": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e107534527434f90b347464f2e19414a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13a2e62e04e2481e88fba1e3c763fbcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffe4d8751f7e41fc8a03a0fec05f737d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41424436154a4f649a44580ed3d5226e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24810aa1f5864a61a51b3323540b8028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be9a26726b0e470c85f8d807a899085d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d6d0d92d6814d8da167134c9b8170a8",
              "IPY_MODEL_c2b331d7433c4766ba5842276c917194",
              "IPY_MODEL_6927f4575b9746fbb045be1170f5c7b0"
            ],
            "layout": "IPY_MODEL_39601551ccbb463b97aad50ddc8af02f"
          }
        },
        "8d6d0d92d6814d8da167134c9b8170a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e856ae77b234e4e808686af82f32c2d",
            "placeholder": "​",
            "style": "IPY_MODEL_299fb129ee3e48a4b0a177be12798ea7",
            "value": "model-00003-of-00003.safetensors: 100%"
          }
        },
        "c2b331d7433c4766ba5842276c917194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe776097aac840798fb2807613b2da79",
            "max": 429448016,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9f845a7e1dbb49c1b92d72e834d18253",
            "value": 429448016
          }
        },
        "6927f4575b9746fbb045be1170f5c7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dae7109032a245509cde1872516a5ac1",
            "placeholder": "​",
            "style": "IPY_MODEL_5d567f381732494aac5b3b2866055f0b",
            "value": " 429M/429M [00:33&lt;00:00, 27.3MB/s]"
          }
        },
        "39601551ccbb463b97aad50ddc8af02f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e856ae77b234e4e808686af82f32c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "299fb129ee3e48a4b0a177be12798ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe776097aac840798fb2807613b2da79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f845a7e1dbb49c1b92d72e834d18253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dae7109032a245509cde1872516a5ac1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d567f381732494aac5b3b2866055f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f0fb66a4688437594cf35f18313d6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e27661ae084f474da835107076884c96",
              "IPY_MODEL_ca436c904c264211b2ba12ece304e322",
              "IPY_MODEL_b4254326fe6f439db62e120c0fccf210"
            ],
            "layout": "IPY_MODEL_50b05093f2c14221be19773d0c55e845"
          }
        },
        "e27661ae084f474da835107076884c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cdc013c76934cd188ea84f7c1a6e98a",
            "placeholder": "​",
            "style": "IPY_MODEL_dea3fce4e6b14461b2777cdf6e324969",
            "value": "model-00002-of-00003.safetensors: 100%"
          }
        },
        "ca436c904c264211b2ba12ece304e322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d4925949c5842208210f60e259a3885",
            "max": 1993062424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52fe0552a09e4f30a79320a33df349b8",
            "value": 1993062424
          }
        },
        "b4254326fe6f439db62e120c0fccf210": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d72a07c5e84e08a935f5bddb6cefc1",
            "placeholder": "​",
            "style": "IPY_MODEL_fa69746380be48e88d8009a19df7d1cf",
            "value": " 1.99G/1.99G [01:23&lt;00:00, 21.3MB/s]"
          }
        },
        "50b05093f2c14221be19773d0c55e845": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cdc013c76934cd188ea84f7c1a6e98a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dea3fce4e6b14461b2777cdf6e324969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d4925949c5842208210f60e259a3885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52fe0552a09e4f30a79320a33df349b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1d72a07c5e84e08a935f5bddb6cefc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa69746380be48e88d8009a19df7d1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "afc27e4e05eb4c7796e892cc17c742c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62326fef6290413b9d4a42eb7a4ac88f",
              "IPY_MODEL_d3d8fd42b6f14310be510c0e7c6ab730",
              "IPY_MODEL_54801faf9f45432ca704466c1904c205"
            ],
            "layout": "IPY_MODEL_ca44be2a94e446128c8fe31b5e0993c1"
          }
        },
        "62326fef6290413b9d4a42eb7a4ac88f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afcbefe2b6344557864ef383add76ece",
            "placeholder": "​",
            "style": "IPY_MODEL_8386bd12e24a47aba238d0eb0c351300",
            "value": "Upload 4 LFS files: 100%"
          }
        },
        "d3d8fd42b6f14310be510c0e7c6ab730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_162a66ea8fd146539373a693ebeaed7a",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3d599f96ed545019be52294a1d741a4",
            "value": 4
          }
        },
        "54801faf9f45432ca704466c1904c205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1b849c9d53546c590ae21ca3760a099",
            "placeholder": "​",
            "style": "IPY_MODEL_f6ae6d6062a04064b383587c27d14baf",
            "value": " 4/4 [01:24&lt;00:00, 35.25s/it]"
          }
        },
        "ca44be2a94e446128c8fe31b5e0993c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afcbefe2b6344557864ef383add76ece": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8386bd12e24a47aba238d0eb0c351300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "162a66ea8fd146539373a693ebeaed7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3d599f96ed545019be52294a1d741a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1b849c9d53546c590ae21ca3760a099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ae6d6062a04064b383587c27d14baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fa3ab92428c401c8b2489c716cd7368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5c34eab4d0f94fd3a1cee8c9cf7092eb",
              "IPY_MODEL_b4807baf9dd748d5aac967a08d37cf04",
              "IPY_MODEL_70fa4ebae49c41b0a937748d021ce025"
            ],
            "layout": "IPY_MODEL_d753f229695246c194458a9d34fcd412"
          }
        },
        "5c34eab4d0f94fd3a1cee8c9cf7092eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3d259a32d1245cbaad4a1a2655e74bf",
            "placeholder": "​",
            "style": "IPY_MODEL_e5ec7282ac174ff1bef045ed124a7bc9",
            "value": "tokenizer.json: 100%"
          }
        },
        "b4807baf9dd748d5aac967a08d37cf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4479cd0b3d494cccb901f719a9ca6605",
            "max": 11420371,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87e764cc25644dc296d4622952e20965",
            "value": 11420371
          }
        },
        "70fa4ebae49c41b0a937748d021ce025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a85c59d70e4f452fabc28fa61c805e2f",
            "placeholder": "​",
            "style": "IPY_MODEL_8792cdea158544619994a7137d24a088",
            "value": " 11.4M/11.4M [00:01&lt;00:00, 62.7MB/s]"
          }
        },
        "d753f229695246c194458a9d34fcd412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3d259a32d1245cbaad4a1a2655e74bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ec7282ac174ff1bef045ed124a7bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4479cd0b3d494cccb901f719a9ca6605": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87e764cc25644dc296d4622952e20965": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a85c59d70e4f452fabc28fa61c805e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8792cdea158544619994a7137d24a088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}